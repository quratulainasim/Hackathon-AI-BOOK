"use strict";(globalThis.webpackChunkphysical_ai_robotics_book=globalThis.webpackChunkphysical_ai_robotics_book||[]).push([[581],{5610:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Introduction","items":[{"type":"link","label":"Physical AI","href":"/docs/introduction/physical-ai","docId":"introduction/physical-ai","unlisted":false},{"type":"link","label":"Humanoid Architecture","href":"/docs/introduction/humanoid-architecture","docId":"introduction/humanoid-architecture","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"ROS 2 Fundamentals","items":[{"type":"link","label":"ROS 2 Fundamentals","href":"/docs/ros2-fundamentals/","docId":"ros2-fundamentals/ros2-fundamentals","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Digital Twin Simulation","items":[{"type":"link","label":"Digital Twin Simulation","href":"/docs/digital-twin-sim/digital-twin-simulation","docId":"digital-twin-sim/digital-twin-simulation","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"NVIDIA Isaac Platform","items":[{"type":"link","label":"NVIDIA Isaac","href":"/docs/nvidia-isaac/","docId":"nvidia-isaac/nvidia-isaac","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Vision-Language-Action for Humanoids","items":[{"type":"link","label":"Vision-Language-Action","href":"/docs/vla-humanoids/vision-language-action","docId":"vla-humanoids/vision-language-action","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Capstone System Overview","items":[{"type":"link","label":"Capstone Overview","href":"/docs/capstone-overview/","docId":"capstone-overview/capstone-overview","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Appendices","items":[{"type":"link","label":"Glossary","href":"/docs/appendices/glossary","docId":"appendices/glossary","unlisted":false},{"type":"link","label":"References","href":"/docs/appendices/references","docId":"appendices/references","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"appendices/glossary":{"id":"appendices/glossary","title":"Glossary","description":"This glossary provides definitions for key terms and concepts used throughout the book, related to Physical AI, humanoid robotics, ROS 2, digital twin simulation, NVIDIA Isaac, and Vision-Language-Action systems.","sidebar":"tutorialSidebar"},"appendices/references":{"id":"appendices/references","title":"References","description":"This section provides a comprehensive list of all sources cited throughout the \\"Physical AI & Humanoid Robotics Book,\\" formatted according to APA 7th edition guidelines. This list includes academic papers, technical documentation, books, and other relevant materials that informed the content of this work. A minimum of 15 sources, with at least 50% peer-reviewed academic articles, have been integrated to ensure the scientific rigor and credibility of the material presented.","sidebar":"tutorialSidebar"},"capstone-overview/capstone-overview":{"id":"capstone-overview/capstone-overview","title":"Capstone Overview","description":"This chapter provides a high-level overview of the integrated Capstone System, bringing together the concepts of Physical AI, ROS 2 fundamentals, Digital Twin Simulation, NVIDIA Isaac Platform, and Vision-Language-Action (VLA) for Humanoids into a cohesive functional architecture. It describes how these individual components interoperate to form a complete humanoid robotics solution capable of understanding natural language, perceiving its environment, planning actions, and executing them in a physical or simulated space.","sidebar":"tutorialSidebar"},"digital-twin-sim/digital-twin-simulation":{"id":"digital-twin-sim/digital-twin-simulation","title":"Digital Twin Simulation","description":"Digital twin simulation plays a crucial role in the development and testing of physical AI and humanoid robots. A digital twin is a virtual replica of a physical system, allowing for experimentation and analysis in a safe and cost-effective environment.","sidebar":"tutorialSidebar"},"introduction/humanoid-architecture":{"id":"introduction/humanoid-architecture","title":"Humanoid Architecture","description":"Humanoid Robot Architecture","sidebar":"tutorialSidebar"},"introduction/physical-ai":{"id":"introduction/physical-ai","title":"Physical AI","description":"What is Physical AI?","sidebar":"tutorialSidebar"},"nvidia-isaac/nvidia-isaac":{"id":"nvidia-isaac/nvidia-isaac","title":"NVIDIA Isaac","description":"NVIDIA Isaac is a comprehensive platform for robotics development, offering tools and resources for simulation, AI-powered perception, navigation, and manipulation. It leverages NVIDIA\'s expertise in GPUs and AI to accelerate the development of autonomous robots, particularly in areas like factory automation, logistics, and humanoid robotics.","sidebar":"tutorialSidebar"},"ros2-fundamentals/ros2-fundamentals":{"id":"ros2-fundamentals/ros2-fundamentals","title":"ROS 2 Fundamentals","description":"ROS 2 (Robot Operating System 2) is a flexible framework for writing robot software. It is a collection of tools, libraries, and conventions that aim to simplify the task of creating complex and robust robot behavior across a wide variety of robotic platforms.","sidebar":"tutorialSidebar"},"vla-humanoids/vision-language-action":{"id":"vla-humanoids/vision-language-action","title":"Vision-Language-Action","description":"Vision-Language-Action (VLA) robotics is an emerging field that aims to enable robots to understand and execute complex instructions given in natural language, leveraging advances in large language models (LLMs) and multimodal AI. For humanoid robots, VLA allows for more intuitive and flexible interaction with human users and complex environments.","sidebar":"tutorialSidebar"}}}')}}]);