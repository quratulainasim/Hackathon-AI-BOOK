{
  "id": "vla-humanoids/vla-humanoids",
  "title": "Vision-Language-Action for Humanoids",
  "description": "Vision-Language-Action (VLA) robotics is an emerging field that aims to enable robots to understand and execute complex instructions given in natural language, leveraging advances in large language models (LLMs) and multimodal AI. For humanoid robots, VLA allows for more intuitive and flexible interaction with human users and complex environments.",
  "source": "@site/docs/vla-humanoids/index.md",
  "sourceDirName": "vla-humanoids",
  "slug": "/vla-humanoids/",
  "permalink": "/docs/vla-humanoids/",
  "draft": false,
  "unlisted": false,
  "tags": [],
  "version": "current",
  "frontMatter": {
    "id": "vla-humanoids",
    "title": "Vision-Language-Action for Humanoids",
    "sidebar_label": "Vision-Language-Action for Humanoids"
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "NVIDIA Isaac",
    "permalink": "/docs/nvidia-isaac/"
  },
  "next": {
    "title": "Capstone System Overview",
    "permalink": "/docs/capstone-overview/"
  }
}